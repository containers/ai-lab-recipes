
version: v1.0
application:
  type: language
  name: chatbot
  description: This is a LLM chatbot application that can interact with a llamacpp model-service
  containers:
    - name: chatbot-inference-app
      contextdir: ai_applications
      containerfile: builds/Containerfile
    - name: chatbot-model-service
      contextdir: model_services
      containerfile: base/Containerfile
      model-service: true
      backend: 
        - llama
      arch:
        - arm64
        - amd64
    - name: chatbot-model-servicecuda
      contextdir: model_services
      containerfile: cuda/Containerfile
      model-service: true 
      backend: 
        - llama
      gpu-env:
        - cuda
      arch: 
        - amd64