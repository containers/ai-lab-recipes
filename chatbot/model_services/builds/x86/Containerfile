FROM quay.io/opendatahub/workbench-images:cuda-ubi9-python-3.9-20231206
WORKDIR /locallm
COPY builds/requirements.txt /locallm/requirements.txt
RUN pip install --upgrade pip
ENV CMAKE_ARGS="-DLLAMA_CUBLAS=on"
ENV FORCE_CMAKE=1
RUN pip install --upgrade --force-reinstall --no-cache-dir -r /locallm/requirements.txt
ENV MODEL_PATH=builds/llama-2-7b-chat.Q5_K_S.gguf
COPY ${MODEL_FILE} /locallm/models/
COPY builds/src/ /locallm
COPY chat_service.py /locallm/chat_service.py
ENTRYPOINT [ "python", "chat_service.py" ]
