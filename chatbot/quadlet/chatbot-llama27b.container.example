[Unit]
Description=Python script to run against downloaded LLM
Documentation=man:podman-generate-systemd(1)
Wants=network-online.target
After=network-online.target
RequiresMountsFor=%t/containers

[Container]
Image=quay.io/sallyom/chatbot:model-service
Label=io.containers.autoupdate=registry
PublishPort=7860:7860
User=0
Environment=MODEL_PATH=/locallm/models/model/llama-2-7b-chat.Q5_K_S.gguf
Mount=type=image,source=quay.io/sallyom/models:llama2-7b-chat-gguf,destination=/locallm/models,rw=true
PodmanArgs=--rm
PodmanArgs=-it

[Service]
Restart=always

[Install]
WantedBy=default.target
