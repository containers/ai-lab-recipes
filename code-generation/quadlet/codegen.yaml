apiVersion: v1
kind: Pod
metadata:
  labels:
    app: codegen-langchain
  name: codegen-langchain
spec:
  initContainers:
  - name: model-file
    image: quay.io/redhat-et/locallm-codellama-7b-gguf:latest
    command: ['/usr/bin/install', "/model/codellama-7b-instruct.Q4_K_M.gguf", "/shared/"]
    volumeMounts:
    - name: model-file
      mountPath: /shared
  containers:
  - env:
    - name: MODEL_SERVICE_ENDPOINT
      value: http://0.0.0.0:8001/v1
    image: quay.io/redhat-et/locallm-codegen:latest
    name: codegen-inference
    ports:
    - containerPort: 8501
      hostPort: 8501
    securityContext:
      runAsNonRoot: true
  - env:
    - name: HOST
      value: 0.0.0.0
    - name: PORT
      value: 8001
    - name: MODEL_PATH
      value: /model/codellama-7b-instruct.Q4_K_M.gguf
    image: quay.io/redhat-et/locallm-model-service:latest
    name: codegen-model-service
    ports:
    - containerPort: 8001
      hostPort: 8001
    securityContext:
      runAsNonRoot: true
    volumeMounts:
    - name: model-file
      mountPath: /model
  volumes:
  - name: model-file
    emptyDir: {}
