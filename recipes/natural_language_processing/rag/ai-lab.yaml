version: v1.0
application:
  type: language
  name: rag-demo
  description: A RAG chat bot using local documents.
  containers:
    - name: llamacpp-server
      contextdir: ../../../model_servers/llamacpp_python
      containerfile: ./base/Containerfile
      model-service: true
      backend:
        - llama
      arch:
        - arm64
        - amd64
      ports:
        - 8001
      image: quay.io/ai-lab/llamacpp_python:latest
    - name: llamacpp-server-cuda
      contextdir: ../../../model_servers/llamacpp_python
      containerfile: ./cuda/Containerfile
      model-service: true
      backend:
        - llama
      arch:
        - amd64
      gpu-env:
        - cuda
      ports:
        - 8001
      image: quay.io/ai-lab/llamacpp_python_cuda:latest
    - name: llamacpp-server-metal
      contextdir: ../../../model_servers/llamacpp_python
      containerfile: ./vulkan/arm64/Containerfile
      model-service: true
      backend:
        - llama
      arch:
        - arm64
      gpu-env:
        - metal      
      ports:
        - 8001
      image: quay.io/ai-lab/llamacpp_python_vulkan:latest      
    - name: chromadb-server
      contextdir: ../../../vector_dbs/chromadb
      containerfile: Containerfile
      vectordb: true
      arch:
        - arm64
        - amd64
      ports:
        - 8000
      image: quay.io/ai-lab/chromadb:latest
    - name: rag-inference-app
      contextdir: app
      containerfile: Containerfile
      arch:
        - arm64
        - amd64
      ports:
        - 8501
      image: quay.io/ai-lab/rag:latest
