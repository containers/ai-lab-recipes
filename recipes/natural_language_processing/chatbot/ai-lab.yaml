version: v1.0
application:
  type: language
  name: ChatBot_Streamlit
  description: Chat with a model service in a web frontend.
  containers:
    - name: llamacpp-server
      contextdir: ../../../model_servers/llamacpp_python
      containerfile: ./base/Containerfile
      model-service: true
      backend:
        - llama
      arch:
        - arm64
        - amd64
      ports:
        - 8001
      image: quay.io/ai-lab/llamacppp_python:latest
    - name: llamacpp-server-cuda
      contextdir: ../../../model_servers/llamacpp_python
      containerfile: ./cuda/Containerfile
      model-service: true
      backend:
        - llama
      arch:
        - amd64
      gpu-env:
        - cuda
      ports:
        - 8001
      image: quay.io/ai-lab/llamacppp_python_cuda:latest
    - name: llamacpp-server-metal
      contextdir: ../../../model_servers/llamacpp_python
      containerfile: ./vulkan/arm64/Containerfile
      model-service: true
      backend:
        - llama
      arch:
        - arm64
      gpu-env:
        - metal      
      ports:
        - 8001
      image: quay.io/ai-lab/llamacppp_python_vulkan:latest
    - name: streamlit-chat-app
      contextdir: app
      containerfile: Containerfile
      arch:
        - arm64
        - amd64
      ports:
        - 8501
      image: quay.io/ai-lab/chatbot:latest
